{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# for data visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# reading the dataset\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# checking the shapes of the train and test datasets\nprint(\"Shape of train: \", train.shape)\nprint(\"Shape of test: \", test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a39bab6a39bdc2812de3b73756ab6f67d9cb154"},"cell_type":"code","source":"# making copies of train and test\n\n#Save the 'Id' column\ntrain_ID = train['Id']\ntest_ID = test['Id']\n\n#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\ntrain.drop(\"Id\", axis = 1, inplace = True)\ntest.drop(\"Id\", axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8454028c82eb701c9de4ff1a1ef0cfc273064e8"},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.scatter(x = train['GrLivArea'], y = train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6010a05672d2cac4f66b98cc6b3bf5f998f4e5e4"},"cell_type":"code","source":"#Deleting outliers\ntrain = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)\n\n#Check the graphic again\nfig, ax = plt.subplots()\nax.scatter(train['GrLivArea'], train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55ee323f75305ee0a821f9955b8756d0cb498843"},"cell_type":"code","source":"# target variable\n\nfrom scipy import stats\nfrom scipy.stats import norm\n\nsns.distplot(train['SalePrice'] , fit = norm)\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train['SalePrice'])\nprint('mu = {:.2f} and sigma = {:.2f}'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(train['SalePrice'], plot = plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd0d6bb320dbbd26b97285c6a9edf0a447baee5e"},"cell_type":"code","source":"#We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n\n#Check the new distribution \nsns.distplot(train['SalePrice'] , fit = norm)\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train['SalePrice'])\nprint('mu = {:.2f} and sigma = {:.2f}'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(train['SalePrice'], plot = plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51b6e4808fd1a1b7b611aa5ebe68e4c9cb51be73"},"cell_type":"code","source":"# combining the train and test datasets for preprocessing\n\nntrain = train.shape[0]\nntest = test.shape[0]\n\n# creating y-train\ny_train = train.SalePrice.values\n\ncombine = pd.concat([train, test])\ncombine.drop(['SalePrice'], axis = 1, inplace =  True)\n\n# printing the shape of new dataset\ncombine.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8493659ded20717719719b9a60f98d4eb0dec33"},"cell_type":"code","source":"combine_na = (combine.isnull().sum() / len(combine)) * 100\ncombine_na = combine_na.drop(combine_na[combine_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :combine_na})\nmissing_data.head(20)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"969a25f8623999960324f50e1482ee690c45ea21"},"cell_type":"code","source":"# checking is there are any NULL values in the train and test sets\n\ncombine.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"774b666a3d4f75d5d19c49a68cf7142188384f6c"},"cell_type":"code","source":"# ## filling the missing values in the Column Types of BsmtFinSF2\n\n# simply filling the NULL value with none\ncombine['BsmtFinSF2'].fillna(0, inplace = True)\n\n# checking if there are any Null values left\ncombine['BsmtFinSF2'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efcd0ec2290cf2026652dd03d82bb1b89b0ef99a"},"cell_type":"code","source":"# ## filling the missing values in the Column Types of BsmtFinSF1\n\n# simply filling the NULL value with none\ncombine['BsmtFinSF1'].fillna(0, inplace = True)\n\n# checking if there are any Null values left\ncombine['BsmtFinSF1'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"302362621f695a691cb417ef475cc932ed3c79c8"},"cell_type":"code","source":"# ## filling the missing values in the Column Types of BsmtFinType2\n\n# simply filling the NULL value with none\ncombine['BsmtFinType2'].fillna('None', inplace = True)\n\n# checking if there are any Null values left\ncombine['BsmtFinType2'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe7d450134aac27a56d38c38c1b56686f32e07f3"},"cell_type":"code","source":"# ## filling the missing values in the Column Types of BsmtFinType1\n\n# simply filling the NULL value with none\ncombine['BsmtFinType1'].fillna('None', inplace = True)\n\n# checking if there are any Null values left\ncombine['BsmtFinType1'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26b8c611a80b874fa2358237bc28ed1833a735ae"},"cell_type":"code","source":"# ## filling the missing values in the Column Types of BsmtFullBath\n\n# simply filling the NULL value with 0 as it is the most common\ncombine['BsmtFullBath'].fillna(0, inplace = True)\n\n# checking if there are any Null values left\ncombine['BsmtFullBath'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5e28bf496113fcd3a88b8af314cf53b82620b0c"},"cell_type":"code","source":"# ## filling the missing values in the Column Types of BsmtHalfBath\n\n# simply filling the NULL value with 0 as it is the most common\ncombine['BsmtHalfBath'].fillna(0, inplace = True)\n\n# checking if there are any Null values left\ncombine['BsmtHalfBath'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4b50e800bbe9ecf3155ef4c48efbc20a2b82bb3"},"cell_type":"code","source":"# ## filling the missing values in the Column Types of BsmtQual\n\n# simply filling the NULL value with none\ncombine['BsmtQual'].fillna('None', inplace = True)\n\n# checking if there are any Null values left\ncombine['BsmtQual'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a2ef6bfeda67fcc204b369a41e8837591fb3ee6"},"cell_type":"code","source":"# ## filling the missing values in the Column Types of BsmtUnfSF\n\n# simply filling the NULL value with 0 as it is the most common\ncombine['BsmtUnfSF'].fillna(0, inplace = True)\n\n# checking if there are any Null values left\ncombine['BsmtUnfSF'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"963f1001893a8c153d7ad1c9a6fb8d0eda62cb2b"},"cell_type":"code","source":"## filling the missing values in the Column Types of Electrical\n\n# simply filling the NULL value with VinylSd as it is the most common\ncombine['Electrical'].fillna(combine['Electrical'].mode()[0], inplace = True)\n\n# checking if there are any Null values left\ncombine['Electrical'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2201a82a45fd7177c71a65081dc30f8623be75df"},"cell_type":"code","source":"## filling the missing values in the Column Types of Exterior2nd\n\n# simply filling the NULL value with VinylSd as it is the most common\ncombine['Exterior1st'].fillna(combine['Exterior1st'].mode()[0], inplace = True)\n\n# checking if there are any Null values left\ncombine['Exterior1st'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8ddd6d8e66fd4b0b06fd0a2e495be66e11cc68c"},"cell_type":"code","source":"## filling the missing values in the Column Types of Exterior2nd\n\n# simply filling the NULL value with most common value\ncombine['Exterior2nd'].fillna(combine['Exterior2nd'].mode()[0], inplace = True)\n\n# checking if there are any Null values left\ncombine['Exterior2nd'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37b3aff72cc0567f21e0884e0c9be88d7b4c53e0"},"cell_type":"code","source":"## filling the missing values in the Column Types of Fence\n\n# simply filling the NULL value with none\ncombine['Fence'].fillna('None', inplace = True)\n\n# checking if there are any Null values left\ncombine['Fence'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2fa3a5db479e63eb7d27006dde94ac774b9f404"},"cell_type":"code","source":"## filling the missing values in the Column Types of FireplaceQu\n\n# simply filling the NULL value with none\ncombine['FireplaceQu'].fillna('None', inplace = True)\n\n# checking if there are any Null values left\ncombine['FireplaceQu'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8491a0a37752581f37bd1eda0d019616ddb49f0e"},"cell_type":"code","source":"## filling the missing values in the Column Types of MSZoning\n\n# simply filling the NULL value with none\ncombine['MSZoning'].fillna('None', inplace = True)\n\n# checking if there are any Null values left\ncombine['MSZoning'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee4a5206c88618a089f10c69457532f7fc4d8154"},"cell_type":"code","source":"## filling the missing values in the Column Types of MasVnrArea\n\n# simply filling the NULL value with 0\ncombine['MasVnrArea'].fillna(0, inplace = True)\n\n# checking if there are any Null values left\ncombine['MasVnrArea'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4adcf48b40e59a2726fcfc0e2e530496c7bf8c13"},"cell_type":"code","source":"## filling the missing values in the Column Types of MasVnrType\n\n# simply filling the NULL value with none\ncombine['MasVnrType'].fillna('None', inplace = True)\n\n# checking if there are any Null values left\ncombine['MasVnrType'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51d8c71f0c0252d53dad6cf3775e17ca1dc0d8a5"},"cell_type":"code","source":"## filling the missing values in the Column Types of MiscFeature\n\n# simply filling the NULL value with none\ncombine['MiscFeature'].fillna('None', inplace = True)\n\n# checking if there are any Null values left\ncombine['MiscFeature'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a34f34a9973b042a285dee7ec50b6c1af386bdd"},"cell_type":"code","source":"## filling the missing values in the Column Typesof PoolQC\n\n# simply filling the NULL value with Ex as it is the most common\ncombine['PoolQC'].fillna('None', inplace = True)\n\n# checking if there are any Null values left\ncombine['PoolQC'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efc099627e5f2b3d08eed0c28e250f7c745552e8"},"cell_type":"code","source":"## filling the missing values in the Column SaleType\n\n# simply filling the NULL value with WD as it is the most common\ncombine['SaleType'].fillna(combine['SaleType'].mode()[0], inplace = True)\n\n# checking if there are any Null values left\ncombine['SaleType'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"806e477fdacf3852f24640ca1edd5d5d80a27ac7"},"cell_type":"code","source":"# filling the missing values in the Column TotalBsmtSF\n\ncombine['TotalBsmtSF'].fillna(combine['TotalBsmtSF'].mean(), inplace = True)\n\n# checking if there are any Null values left\ncombine['TotalBsmtSF'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"993b0f84f66d3a3a6ece861c989b5d60d5968db2"},"cell_type":"code","source":"# checking the unique value in the column Utlities\n\ncombine['Utilities'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be92515aeb178cb7585c9e1b6becf0a269ceb5d4"},"cell_type":"code","source":"# AS, we just saw that almost all the rows have same value for Utilities we will get rid of this column\n\ncombine.drop(['Utilities'], axis = 1, inplace = True)\n\n# checking the new shape of the dataset\ncombine.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a471c3a28dbcfb38b01c94b985de5b019bc1bcbd"},"cell_type":"code","source":"# filling the missing values in the LotFrontage column\n\n#Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\ncombine[\"LotFrontage\"] = combine.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))\n\n# checking if there are any NULL values left in the LotFronage Column\ncombine['LotFrontage'].isnull().any()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8821f83bc309a45b66f970742e7f8a5259ee42f"},"cell_type":"code","source":"# filling the missing values \n\n# we will replace null values with none\ncombine['Alley'].fillna('None', inplace = True)\n\n# checking if there are any NULL values left\ncombine['Alley'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3338de12429c2bd067f6665f2b3a9c7428ee5eef"},"cell_type":"code","source":"# filling the missing values in the BsmtCond column\n\n# we are simply filling none in the place NULL values \ncombine['BsmtCond'].fillna('None', inplace = True)\n\n# checking if there are any left NULL values\ncombine['BsmtCond'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63c6db7eea6b5e42791f4a1916802f747748927f"},"cell_type":"code","source":"# filling the missing values in the BsmtCond column\n\n# replacing No with None\ncombine['BsmtExposure'].replace(('No'), ('None'), inplace = True)\n\n# we are simply filling None in the place NULL values \ncombine['BsmtExposure'].fillna('None', inplace = True)\n\n# checking if there are any left NULL values\ncombine['BsmtExposure'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"484f18d813ba48f8888f6f6e5566d1e573d74df9"},"cell_type":"code","source":"combine['KitchenQual'].value_counts(dropna = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72544ff7dbd292781b3d024d5984628c09820a37"},"cell_type":"code","source":"# filling the missing values in the KitchenQual column\n\n# we are simply filling TA in the place NULL values \ncombine['KitchenQual'].fillna(combine['KitchenQual'].mode()[0], inplace = True)\n\n# checking if there are any left NULL values\ncombine['KitchenQual'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31212115e2aec2b62789d1bb805dcace5f022b22"},"cell_type":"code","source":"# filling the missing values in the GarageYrBlt column\n\n# we are simply filling none in place of NULL values\ncombine['GarageYrBlt'].fillna('None', inplace = True)\n\n# checking if there are any left NULL values\ncombine['GarageYrBlt'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c718cf68c3dd4935c2cb2267bf9744392855b55d"},"cell_type":"code","source":"# filling the missing values in the GarageType column\n\n# we are simply filling none in the place NULL values \ncombine['GarageType'].fillna('None', inplace = True)\n\n# checking if there are any left NULL values\ncombine['GarageType'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d73e0b2cc73c52de20c3179ee58586b4c7e37a29"},"cell_type":"code","source":"# filling the missing values in the GarageQual column\n\n# we are simply filling none in the place NULL values \ncombine['GarageQual'].fillna('None', inplace = True)\n\n# checking if there are any left NULL values\ncombine['GarageQual'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d402b8ca0ade5639791b03651eb6c12197cd16b"},"cell_type":"code","source":"# filling the missing values in the GarageFinish column\n\n# we are simply filling none in the place NULL values  \ncombine['GarageFinish'].fillna('None', inplace = True)\n\n# checking if there are any left NULL values\ncombine['GarageFinish'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b480fd9509f0ade0fbf1b54b733e6cbc9ba109b4"},"cell_type":"code","source":"# filling the missing values in the GarageCond column\n\n# we are simply filling Unf in the place NULL values \ncombine['GarageCond'].fillna('None', inplace = True)\n\n# checking if there are any left NULL values\ncombine['GarageCond'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6b2bd32f4c395fe243dcf9153a7b96eb90710f9"},"cell_type":"code","source":"# filling the missing values in the GarageCars column\n\n# we are simply filling 0 in the place NULL values \ncombine['GarageCars'].fillna(0, inplace = True)\n\n# checking if there are any left NULL values\ncombine['GarageCars'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f06de47716dc1dedaa6d34ff631bb48da1fd1c5"},"cell_type":"code","source":"# filling the missing values in the GarageArea column\n\n# we are simply filling 0 in the place NULL values \ncombine['GarageArea'].fillna(0, inplace = True)\n\n# checking if there are any left NULL values\ncombine['GarageArea'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"113912a2bc3b63debfafaad6c94f7a8406e0d979"},"cell_type":"code","source":"# filling the missing values in the Functional column\n\ncombine['Functional'].fillna(combine['Functional'].mode()[0], inplace = True)\n\n# checking if there are any left NULL values\ncombine['Functional'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2090825db08ae2698440785f05fd8181006bbce4"},"cell_type":"code","source":"combine.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3445acaa5e214b50ce780e1165bd9ed032ab8430"},"cell_type":"code","source":"# Transforming some numerical variables that are really categorical\n\n#MSSubClass=The building class\ncombine['MSSubClass'] = combine['MSSubClass'].apply(str)\n\n\n#Changing OverallCond into a categorical variable\ncombine['OverallCond'] = combine['OverallCond'].astype(str)\n\n\n#Year and month sold are transformed into categorical features.\ncombine['YrSold'] = combine['YrSold'].astype(str)\ncombine['MoSold'] = combine['MoSold'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7083fab7957ce167a9f7618251bdcb7aea5413b"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ncols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n\n# process columns, apply LabelEncoder to categorical features\nfor c in cols:\n    lb = LabelEncoder() \n    lb.fit(list(combine[c].values)) \n    combine[c] = lb.transform(list(combine[c].values))\n\n# shape        \nprint('Shape all_data: {}'.format(combine.shape))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb4398b3b1de9f4dd83105975456fc5ffa5be015"},"cell_type":"code","source":"# FEATURE ENGINEERING\n# adding a new column total area as it is big determinant for prices of a home.\n\ncombine['total_area'] = combine['1stFlrSF'] + combine['2ndFlrSF'] + combine['TotalBsmtSF']\n\n# looking at the new shape of the combine dataset\ncombine.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa3b3809e6c97e959c09e43347d090f9a25b3d4e"},"cell_type":"code","source":"# finding skewed features\n\nfrom scipy.stats import skew\n\nnumerical_feats = combine.dtypes[combine.dtypes != 'object'].index\n\n# checking the skewness in all the numerical features\nskewed_feats = combine[numerical_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending = False)\n\n# converting the features into a dataframe\nskewness = pd.DataFrame({'skew':skewed_feats})\n\n# checking the head of skewness dataset\nskewness.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"914aa4945c486c413f17e523f0f2ad95abdc14b3"},"cell_type":"code","source":"# applying box-cox transformations\n\nskewness = skewness[abs(skewness > 0.8)]\n\n# printing how many features are to be box-cox transformed\nprint(\"There are {} skewed numerical features to box cox transform\".format(skewness.shape[0]))\n\n# importing box-cox1p\nfrom scipy.special import boxcox1p\n\n# defining skewed features\nskewed_features = skewness.index\n\nlam = 0.15\nfor feat in skewed_features:\n    combine[feat] += 1\n    combine[feat] = boxcox1p(combine[feat], lam)\n  \ncombine[skewed_features] = np.log1p(combine[skewed_features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3d11209ccffe99cbaf05302519a2282bc8b8bd2"},"cell_type":"code","source":"# one hot encoding for all the categorical variables\n\ncombine = pd.get_dummies(combine)\n\n# checking the head of the dataset\ncombine.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc217d1a8ccfc084062a53c9a412808fb15a8743"},"cell_type":"code","source":"# separating the train and test datasets\n\nx_train = combine.iloc[:ntrain]\nx_test = combine.iloc[ntrain:]\n\n# checking the shapes of train and test datasets\nprint(\"Shape of train :\", x_train.shape)\nprint(\"Shape of test :\", x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a1e26838dfdbd743455c436605aef845919be08"},"cell_type":"code","source":"#Validation function\nn_folds = 5\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error\n\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(x_train.values)\n    rmse= np.sqrt(-cross_val_score(model, x_train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"0d6315cd7b825b3ee9f9a4dc13133b8c301abd99"},"cell_type":"code","source":"# LASSO MODEL\n# WITH PIPELINE  and using robust scalerTO AVOID SENSITIVITY TOWARDS OUTLIERS\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\n\nfrom sklearn.linear_model import Lasso\n\nlasso = make_pipeline(RobustScaler(), Lasso(alpha = 0.0005, random_state = 3))\nlasso.fit(x_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"a36afc69178c55757debac31f05130aab73ce5a5"},"cell_type":"code","source":"score = rmsle_cv(lasso)\nprint(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"da1d29f003fe1d86923e266369c88171b5fb3674"},"cell_type":"code","source":"# making an Elastic Net model\nfrom sklearn.linear_model import ElasticNet\n\nENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n\nscore = rmsle_cv(ENet)\nprint(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n\nENet.fit(x_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6de8d3b8db2081e46190d1902b654784d152132"},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\n# making a gradint boosting model\nGBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =5)\n\nscore = rmsle_cv(GBoost)\nprint(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f119416b608b5510f75e0de35d131957016075de"},"cell_type":"code","source":"# making predictions\nGBoost.fit(x_train, y_train)\npredictions = GBoost.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6436d584b67063c2330ca55fdf8cb891c3585872"},"cell_type":"code","source":"# light gradient boosting\nimport lightgbm as lgb\n\nmodel_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n\nmodel_lgb.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e3cdceced4916b518682f91b3567054c2bff377"},"cell_type":"code","source":"predictions = model_lgb.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f9c1b69ed7804d5185140b452da44720c69a66f"},"cell_type":"code","source":"# KERNEL RIDGE REGRESSION\n\nfrom sklearn.kernel_ridge import KernelRidge\n\nKRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\nscore = rmsle_cv(KRR)\nprint(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7020fe3f39e05e85f29cc04655789f53d655e6b5"},"cell_type":"code","source":"# STACKING\n# Simplest model -> Averaging Base Models\n\nfrom sklearn.base import BaseEstimator\nfrom sklearn.base import RegressorMixin\nfrom sklearn.base import TransformerMixin\nfrom sklearn.base import clone\n\nclass AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, models):\n        self.models = models\n        \n    # we define clones of the original models to fit the data in\n    def fit(self, X, y):\n        self.models_ = [clone(x) for x in self.models]\n        \n        # Train cloned base models\n        for model in self.models_:\n            model.fit(X, y)\n        return self\n    \n    #Now we do the predictions for cloned models and average them\n    def predict(self, X):\n        predictions = np.column_stack([model.predict(X) for model in self.models_])\n        return np.mean(predictions, axis=1)   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7eb9744781b7812846bcbc2997909d4196d17ad5"},"cell_type":"code","source":"averaged_models = AveragingModels(models = (ENet, GBoost, KRR, lasso))\n\nscore = rmsle_cv(averaged_models)\nprint(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cfb1e75e751f7dd4ba7c8938ab9b281b87384f6"},"cell_type":"code","source":"class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, base_models, meta_model, n_folds=5):\n        self.base_models = base_models\n        self.meta_model = meta_model\n        self.n_folds = n_folds\n   \n    # We again fit the data on clones of the original models\n    def fit(self, X, y):\n        self.base_models_ = [list() for x in self.base_models]\n        self.meta_model_ = clone(self.meta_model)\n        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n        \n        # Train cloned base models then create out-of-fold predictions\n        # that are needed to train the cloned meta-model\n        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n        for i, model in enumerate(self.base_models):\n            for train_index, holdout_index in kfold.split(X, y):\n                instance = clone(model)\n                self.base_models_[i].append(instance)\n                instance.fit(X[train_index], y[train_index])\n                y_pred = instance.predict(X[holdout_index])\n                out_of_fold_predictions[holdout_index, i] = y_pred\n                \n        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n        self.meta_model_.fit(out_of_fold_predictions, y)\n        return self\n   \n    #Do the predictions of all base models on the test data and use the averaged predictions as \n    #meta-features for the final prediction which is done by the meta-model\n    def predict(self, X):\n        meta_features = np.column_stack([\n            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n            for base_models in self.base_models_ ])\n        return self.meta_model_.predict(meta_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a0210a4805b060438b6a6efc15d6b9a15e71738"},"cell_type":"code","source":"stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n                                                 meta_model = lasso)\n\nscore = rmsle_cv(stacked_averaged_models)\nprint(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cee4675433d0cf772fc54dc97fac8e16eb8d35ec"},"cell_type":"code","source":"def rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d4443a10ebbfec9a7029777ce18e5b0391959b8"},"cell_type":"code","source":"stacked_averaged_models.fit(x_train.values, y_train)\nstacked_train_pred = stacked_averaged_models.predict(x_train.values)\nstacked_pred = np.expm1(stacked_averaged_models.predict(x_test.values))\nprint(rmsle(y_train, stacked_train_pred))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d43a58980458b25b43d81684dcb0316bff0a21e2"},"cell_type":"code","source":"# XG BOOST\nimport xgboost as xgb\n\nmodel_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1)\n\nscore = rmsle_cv(model_xgb)\nprint(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cca2e8a2f402f0526c5d648f22581abba35cbf8","scrolled":true},"cell_type":"code","source":"model_xgb.fit(x_train, y_train)\nxgb_train_pred = model_xgb.predict(x_train)\nxgb_pred = np.expm1(model_xgb.predict(x_test))\nprint(rmsle(y_train, xgb_train_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe32eb242566c65c02dab2ecf89ee30d3631a368"},"cell_type":"code","source":"model_lgb.fit(x_train, y_train)\nlgb_train_pred = model_lgb.predict(x_train)\nlgb_pred = np.expm1(model_lgb.predict(x_test.values))\nprint(rmsle(y_train, lgb_train_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eaa5d4c616b9961aed6283fb9579371a77765145"},"cell_type":"code","source":"'''RMSE on the entire Train data when averaging'''\n\nprint('RMSLE score on train data:')\nprint(rmsle(y_train,stacked_train_pred*0.70 +\n               xgb_train_pred*0.15 + lgb_train_pred*0.15 ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"926add869e3e4316b82e49c2b2dd76a346e09b19"},"cell_type":"code","source":"predictions = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66227a1c2f9326a283f04112e7c96e32477a91fb"},"cell_type":"code","source":"#Create a  DataFrame with the passengers ids and our prediction regarding whether they survived or not\n\nsubmission = pd.DataFrame({'Id': test_ID,'SalePrice': predictions})\n\n#Visualize the first 5 rows\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3bd6aafb8e36e1a9e3defa24eceb00f00f21ec19"},"cell_type":"code","source":"#Convert DataFrame to a csv file that can be uploaded\n#This is saved in the same directory as your notebook\nfilename = 'submission.csv'\n\nsubmission.to_csv(filename, index=False)\n\nprint('Saved file: ' + filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c0593ef33d7ef8c0d4d0f8e53c9fd548d4a1b09"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}